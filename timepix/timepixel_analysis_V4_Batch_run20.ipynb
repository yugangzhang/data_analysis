{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chxanalys.chx_packages import *\n",
    "%matplotlib notebook\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "plt.rcParams.update({ 'image.origin': 'lower'   })\n",
    "plt.rcParams.update({ 'image.interpolation': 'none'   })\n",
    "import pickle as cpk\n",
    "from chxanalys.chx_xpcs_xsvs_jupyter_V1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scat_geometry ='saxs'\n",
    "qphi_analysis = False\n",
    "run_t_ROI_Inten = True\n",
    "use_sqnorm = True\n",
    "use_imgsum_norm = True\n",
    "run_one_time = True\n",
    "bad_frame_list = None\n",
    "good_start = 0\n",
    "fit_g2_func = 'stretched'\n",
    "\n",
    "run_two_time =   True    #run  two-time\n",
    "run_four_time = False #True #False   #run  four-time\n",
    "run_xsvs=  False #False         #run visibility analysis\n",
    "att_pdf_report = True    #attach the pdf report to CHX olog\n",
    "qth_interest = 1 #the intested single qth             \n",
    "use_sqnorm = True    #if True, use sq to normalize intensity\n",
    "use_imgsum_norm= True  #if True use imgsum to normalize intensity for one-time calculatoin\n",
    "pdf_version='_%s'%get_today_date()     #for pdf report name\n",
    "run_dose =  False #True  #run dose_depend analysis\n",
    "\n",
    "if scat_geometry == 'gi_saxs':run_xsvs= False;use_sqnorm=False\n",
    "if scat_geometry == 'gi_waxs':use_sqnorm = False;\n",
    "if scat_geometry != 'saxs':qphi_analysis = False;scat_geometry_ = scat_geometry  \n",
    "else:scat_geometry_ = ['','ang_'][qphi_analysis]+ scat_geometry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sample info\n",
    "\n",
    "T= True\n",
    "F = False\n",
    "\n",
    "\n",
    "#chx_THL230_15s_11_W0028_H11-171113-172644-1.csv\n",
    "#--> count : 1 ['8452c7'] (scan num: 9195) (Measurement: Timpix3 1s series file chx_THL230_11s_10: exp_1s Silica 250 nm diam, stock solution in water )\n",
    "    \n",
    "sam = dict(  \n",
    "run11 =  'chx_THL230_15s_11_W0028_H11-171113-172644-1.csv',\n",
    "run16 = 'chx_THL230_15s_16_W0028_H11-171114-041148-1.csv', \n",
    "run20 = 'chx_THL230_3600s_20_W0028_H11-171114-063246.csv',    \n",
    "    \n",
    "mask  =  'W0028_H11_trimdacs.txt'\n",
    "    \n",
    ")    \n",
    "\n",
    "#save_dict_csv(sam, out_dir0 + 'sample_info.csv')\n",
    "\n",
    "data_dir = '/XF11ID/analysis/2017_3/Timepix/Data/'\n",
    "out_dir0 = '/XF11ID/analysis/2017_3/Timepix/Results/'\n",
    "\n",
    "out_dir0 = '/home/yuzhang/Analysis/Timepix/2017_3/Results/'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /XF11ID/analysis/2017_3/Timepix/Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chxanalys.chx_packages import *\n",
    "%matplotlib notebook\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "#%reset -f  #for clean up things in the memory\n",
    "import pandas as pds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide sample filename here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = '11'\n",
    "thresh = 230\n",
    "uid = 'run%s'%run\n",
    "fp = sam[ uid ]\n",
    "print( uid, fp  ) \n",
    "\n",
    "out_dir = os.path.join(out_dir0, '%s/'%uid)\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "print('Results from this analysis will be stashed in the directory %s' %out_dir)\n",
    "uidstr = 'uid=%s'%uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run /XF11ID/analysis/Analysis_Pipelines/Develop/chxanalys/chxanalys/xpcs_timepixel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_unit = 25/4096/1e9#  * this time_unit to make scale in s\n",
    "print(time_unit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y,t0 = get_timepixel_data( data_dir, fp,time_unit=1 )\n",
    "t = t0 * time_unit\n",
    "#print( 'The max time is %s ms' %( t.max()*6.1/1e9) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'The time duration is %s s.' %t.max()  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot1D(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Due to shutter open chose data from 100 to -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    x = x[100:-100]\n",
    "    y = y[100:-100]\n",
    "    t = t[100:-100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Time~Intensity Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbin_step = 0.001 * 1  #in unit of s\n",
    "times, imgsum = get_his_taus( t, bin_step = tbin_step )\n",
    "#times in ms\n",
    "print(times.shape) \n",
    "timeperframe =  tbin_step \n",
    "print ( timeperframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot1D( x = times, y= imgsum , m='o', c='b', ls = '--',save=True, path= out_dir,\n",
    "     title='%s_imgsum_time'%uid, xlabel = r\"$time $ $(s)$\", ylabel = 'Photon Counts of Image Sum' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run /XF11ID/analysis/Analysis_Pipelines/Develop/chxanalys/chxanalys/chx_generic_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 1.2e4\n",
    "w= np.where( imgsum >thres )\n",
    "t1,t2= times[ w[0][0] ], times[ w[0][-1] ]\n",
    "t1_ind, t2_ind =  find_index(t,t1), find_index(t,t2)\n",
    "print( t1,t2, t1_ind, t2_ind  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get interested time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#t1_ind, t2_ind = 0, 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xeff = x[t1_ind:t2_ind] \n",
    "yeff = y[t1_ind:t2_ind] \n",
    "poseff = xeff * 256 + yeff\n",
    "t0eff =t0[t1_ind:t2_ind] - t0[t1_ind]\n",
    "teff = t0eff * time_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tbin_step = 0.01 * 1  #in unit of s\n",
    "times, imgsum = get_his_taus( teff, bin_step = tbin_step )\n",
    "#times in ms\n",
    "print(times.shape) \n",
    "timeperframe =  tbin_step \n",
    "print ( timeperframe)\n",
    "\n",
    "plot1D( x = times, y= imgsum , m='o', c='b', ls = '--',save=True, path= out_dir,\n",
    "     title='%s_imgsum_time'%uid, xlabel = r\"$time $ $(s)$\", ylabel = 'Photon Counts of Image Sum' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get/Create Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = np.loadtxt( data_dir + sam['mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mask = np.zeros( [256, 256] )\n",
    "mask = 1 - m[:,3].reshape( [256, 256 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edg = 2\n",
    "mask[:edg,:] = 0\n",
    "mask[-edg:,:] = 0\n",
    "mask[:,:edg] = 0\n",
    "mask[:,-edg:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img( mask )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run /XF11ID/analysis/Analysis_Pipelines/Develop/chxanalys/chxanalys/xpcs_timepixel.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Averaged Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_img = get_timepixel_avg_image( xeff,yeff,teff,  delta_time = None ) * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img( avg_img,  alpha=0.8, vmin=0.0001, vmax= 5e9, logs=True, aspect=1,  \n",
    "          \n",
    "         image_name= '%s_img_avg'%uid,  save=True, path= out_dir,  cmap = cmap_albula )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "center = [ 256, 280 ] #center0 is the image x, center1 is the image y  #actually this is good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rmk = create_ring_mask( [256, 256],  282, 292, center= center ) * mask\n",
    "r1d = avg_img[np.array(rmk, dtype=bool) ].ravel()\n",
    "plot1D(  r1d, c='b', m='o'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#avg_img = get_timepixel_avg_image( xeff,yeff,teff,  delta_time = None )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img( avg_img, label_array = None, alpha=0.4, vmin=5, vmax= 5e4, logs=True, aspect=1, center= center[::-1],           \n",
    "         image_name= '%s_img_avg'%uid,  save=True, path= out_dir,  cmap = cmap_albula )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Do a circular average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setup_pargs = {'Ldet': 16035 + 0,  'center': center,\n",
    "               'dpix': 0.046,  #what's pixel size, should be 45 um???\n",
    "               'exposuretime':  0.001, 'lambda_': 1.28481,\n",
    "            'path': out_dir,  \n",
    "               'uid': 'uid=Run11'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#avg_img_ = FD.rdframe(0) * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#avg_img_ =  get_avg_imgc(FD,sampling=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp_saxs, iq_saxs, q_saxs = get_circular_average( avg_img, mask, pargs=setup_pargs  )\n",
    "plot_circular_average( qp_saxs, iq_saxs, q_saxs,  pargs=setup_pargs,  \n",
    "                  xlim=[q_saxs.min(), q_saxs.max()*1.0], ylim = [iq_saxs.min(), iq_saxs.max()] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iqdir = '/XF11ID/analysis/2017_3/yuzhang/Results/cb9605/'\n",
    "fuid = 'cb9605fa-b9ea-41fb-afb1-3940ecc0fa84'\n",
    "extract_dict = extract_xpcs_results_from_h5( filename = 'uid=%s_Res.h5'%fuid, import_dir = iqdir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot1D( x= extract_dict['q_saxs'], y= extract_dict[ 'iq_saxs' ], ax =ax, legend='4M', m='s',c='k' )\n",
    "plot1D( x=q_saxs, y= iq_saxs * 100, ax =ax, legend='Timepix', m='o',c='b', logy=True, xlim=[0., 0.01], ylim=[0.01,100] )\n",
    "ax.vlines( 0.00316, 0.,10 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ring-shaped ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if scat_geometry =='saxs':    \n",
    "    uniformq =  True  #True # False    \n",
    "    ## Define ROI\n",
    "    #* Create ring mask defined by  inner_radius, outer_radius, width, num_rings (all in pixel unit)\n",
    "    #* Create ring mask defined by  edges (all in pixel unit)    \n",
    "    ### Define a non-uniform distributed rings by giving edges\n",
    "    if not uniformq:\n",
    "        \n",
    "        qcenters = [  0.0023,  0.00365, 0.0050, ]#0.00621, 0.00754, 0.00880  ] #in A-1        \n",
    "        #width = 0.0001  # in A-1         \n",
    "        #width =    [0.0001,      0.00012,  0.00014,  0.00016, 0.00018,  0.0002,  0.00022 ]\n",
    "        width =    np.array( [0.0001,      0.00012,  0.00014,  0.00016, 0.00018,  0.0002,  0.00022 ] ) * 3.5\n",
    "        \n",
    "        edges = get_non_uniform_edges(  qcenters, width, number_rings =1 )    \n",
    "        inner_radius= None\n",
    "        outer_radius = None\n",
    "        width = None\n",
    "        num_rings = None        \n",
    "    # Define a uniform distributed rings by giving inner_radius, outer_radius, width, num_rings (all in pixel unit)\n",
    "    if uniformq:            \n",
    "        inner_radius= 0.0026 #0.006  #16\n",
    "        outer_radius = 0.0050 #0.05  #112    \n",
    "        num_rings = 12 #18\n",
    "        gap_ring_number = 0.1\n",
    "        width =    ( outer_radius - inner_radius)/(num_rings + gap_ring_number)\n",
    "        edges = None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scat_geometry =='saxs':\n",
    "    roi_mask, qr, qr_edge = get_ring_mask(  mask, inner_radius=inner_radius, \n",
    "            outer_radius = outer_radius , width = width, num_rings = num_rings, edges=edges,\n",
    "                          unit='A',       pargs=setup_pargs   )\n",
    "    qind, pixelist = roi.extract_label_indices(  roi_mask  ) \n",
    "    qr = np.round( qr, 5)\n",
    "    print(len(qr))\n",
    "    \n",
    "    #show_ROI_on_image( avg_img, roi_mask, center, label_on = False, rwidth = 140, alpha=.9,  \n",
    "    #                 save=True, path=data_dir, uid=uidstr, vmin= np.min(avg_img), vmax= np.max(avg_img),\n",
    "    #                 aspect=1) \n",
    "    qval_dict = get_qval_dict( np.round(qr, 5)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#show_img(roi_mask * mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img( avg_img, label_array = roi_mask, alpha=0.4, vmin=5, vmax= 5e5, logs=True, aspect=1, center= center[::-1],           \n",
    "         image_name= '%s_img_avg'%uid,  save=True, path= out_dir,  cmap = cmap_albula )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_qIq_with_ROI??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#show_img( avg_img, label_array = roi_mask, alpha=0.4, vmin=5, vmax= 5e5, logs=True, aspect=1, center= center[::-1],           \n",
    "#         image_name= '%s_img_avg'%uid,  save=True, path= out_dir,  cmap = cmap_albula )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scat_geometry =='saxs':\n",
    "    plot_qIq_with_ROI( q_saxs, iq_saxs, qr, logs=True, uid=uidstr, xlim=[0.002,0.006],\n",
    "                  ylim = [iq_saxs.min(), iq_saxs.max()*2],  save=True, path= out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xeff,yeff,t0eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run /XF11ID/analysis/Analysis_Pipelines/Develop/chxanalys/chxanalys/xpcs_timepixel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbins = 0.01 #10 ms\n",
    "tbins = 0.001 #1 ms\n",
    "tbins = 0.0001 #0.1 ms\n",
    "tbins = 0.00001  #0.01 ms\n",
    "\n",
    "tbins = 0.000001  #0.001 ms, 1 microsecond\n",
    "\n",
    "tbins = 1e-6 *5\n",
    "binstep = int(tbins/time_unit)\n",
    "tinbs = binstep * time_unit\n",
    "    \n",
    "print(binstep, tinbs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_dir\n",
    "\n",
    "\n",
    "\n",
    "tot =  pds.read_csv( data_dir + fp )[' #ToT']\n",
    "toteff = np.array(tot)[t1_ind:t2_ind]\n",
    "\n",
    "#plot1D( np.bincount(toteff) )\n",
    "\n",
    "#w = np.where( (toteff >=150) & (toteff <=500) )[0]\n",
    "\n",
    "#good_time_ind = np.where(diff>500*1e-9)[0]\n",
    "#good_time_ind = np.where( tot*time_unit > 500*1e-9)[0]\n",
    "#good_time_ind = np.where(diff>0)[0]\n",
    "\n",
    "good_time_ind = np.where( (toteff >= 300) & (toteff <= 400) )[0]\n",
    "\n",
    "good_time_ind\n",
    "\n",
    "#len( np.where( diff <=500 )[0] )/len(t0eff)\n",
    "\n",
    "len(good_time_ind)/len(t0eff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = '11'\n",
    "run = '16'\n",
    "run = '20'\n",
    "thresh = 230\n",
    "uid = 'run%s'%run\n",
    "fp = sam[ uid ]\n",
    "print( uid, fp  ) \n",
    "\n",
    "out_dir_ = os.path.join(out_dir0, '%s/'%uid)\n",
    "os.makedirs(out_dir_, exist_ok=True)\n",
    "print('Results from this analysis will be stashed in the directory %s' %out_dir_)\n",
    "uidstr = 'uid=%s'%uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_unit = 25/4096/1e9#  * this time_unit to make scale in s\n",
    "print(time_unit)\n",
    "x,y,tt0 = get_timepixel_data( data_dir, fp,time_unit=1 )\n",
    "t = tt0 * time_unit\n",
    "#print( 'The max time is %s ms' %( t.max()*6.1/1e9) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbin_step = 0.001 * 1  #in unit of s\n",
    "times0, imgsum0 = get_his_taus( t, bin_step = tbin_step )\n",
    "#times in ms\n",
    "print(times0.shape) \n",
    "timeperframe =  tbin_step \n",
    "print ( timeperframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do loop here for one long count with different time ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thres = 2000\n",
    "wimgsum= np.where( imgsum0 > thres )[0]\n",
    "wtimes = times0[wimgsum]\n",
    "ww = np.where( np.diff( wtimes ) >  1)[0]\n",
    "wt = np.zeros( [   len(ww) +1, 2]  )\n",
    "wt[0] = [times0[798], times0[wimgsum][ww][0]]\n",
    "wt[1:-1,0] =  times0[wimgsum][ww+1][:-1]\n",
    "wt[1:-1,1] =    times0[wimgsum][ww][1:]\n",
    "wt[-1] =  [ times0[wimgsum][ww+1][-1], times0[wimgsum][ww+1][-1] +3]\n",
    "#print( wt )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do loop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run /home/yuzhang/chxanalys_link/chxanalys/Create_Report.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for posi in  np.arange(15,25):  \n",
    "    print(posi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for posi in  np.arange(60):\n",
    "for posi in  np.arange(25,60):    \n",
    "    \n",
    "    taus=None;g2=None;tausb=None;g2b=None;\n",
    "    g12b=None;taus4=None;g4=None;times_xsv=None;\n",
    "    contrast_factorL=None; lag_steps = None;\n",
    "    data_pixel=None;\n",
    "    \n",
    "    \n",
    "    print('*'*50)\n",
    "    print('Running for the %s position'%posi)\n",
    "    #for posi in [0]:  \n",
    "    tbins = 0.00001  #10 us\n",
    "    binstep = int(tbins/time_unit)\n",
    "    tinbs = binstep * time_unit\n",
    "    print(binstep, tinbs)    \n",
    "    \n",
    "    uid='run20_pos%s'%(posi+1)\n",
    "    print(uid)\n",
    "    out_dir = os.path.join(out_dir_, '%s/'%uid)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    print('Results from this analysis will be stashed in the directory %s' %out_dir)\n",
    "    uidstr = 'uid=%s'%uid\n",
    "\n",
    "    tw1, tw2 = wt[posi] \n",
    "    #tw1, tw2 = 0.79, 0.80 #for test purpose\n",
    "    \n",
    "    t1_ind, t2_ind =  np.argmin(np.abs(t-tw1)),np.argmin(np.abs(t-tw2))\n",
    "    #print(t1_ind, t2_ind)\n",
    "    print(tw1, tw2)\n",
    "    print(t[t1_ind], t[t2_ind])\n",
    "\n",
    "\n",
    "    xeff = x[t1_ind:t2_ind] \n",
    "    yeff = y[t1_ind:t2_ind] \n",
    "    poseff = xeff * 256 + yeff\n",
    "    t0eff =tt0[t1_ind:t2_ind] - tt0[t1_ind]\n",
    "    teff = t0eff * time_unit    \n",
    "       \n",
    "    md = { 'detector_distance': 16035 + 0,\n",
    "          'beam_center_x': 256,\n",
    "          'beam_center_y': 280,\n",
    "           'x_pixel_size': 0.045,\n",
    "          'y_pixel_size': 0.0045,\n",
    "          'incident_wavelength': 1.28481,\n",
    "          'sx': 256,\n",
    "          'sy':256,\n",
    "         'frame_time': tbins, \n",
    "          'count_time': tbins,\n",
    "           'uid': 'uid=run20_pos%s'%(1+posi)\n",
    "         }\n",
    "\n",
    "    setup_pargs = {'Ldet': 16035 + 0,  'center': center,\n",
    "               'dpix': 0.046,  #what's pixel size, should be 45 um???\n",
    "               'exposuretime':  0.001, 'lambda_': 1.28481,\n",
    "            'path': out_dir,  \n",
    "               'uid': 'uid=run20_pos%s'%(1+posi) }\n",
    "    \n",
    "    filename = out_dir0 + uid + '_tbin=%s.cmp'%tbins\n",
    "    if False:#consider dead time issue\n",
    "        avg_img, imgsum, N = compress_timepix_data( poseff[good_time_ind],\n",
    "                                               t0eff[good_time_ind],\n",
    "                                               binstep, filename = filename, \n",
    "                                               md = md, force_compress= True  )\n",
    "    else:        \n",
    "        avg_img, imgsum, N = compress_timepix_data( poseff,\n",
    "                                                    t0eff,\n",
    "                                               binstep, filename = filename, \n",
    "                                               md = md, force_compress= True  )\n",
    "        \n",
    "    print(N)\n",
    "    FD = Multifile(filename, 0, N  )\n",
    "    uidstr_ = uidstr + 'tbins=%.3f_ms'%( tbins*1000 ) \n",
    "    \n",
    "    good_start = 0\n",
    "    bad_frame_list =[]\n",
    "    plot1D( y = imgsum[ np.array( [i for i in np.arange(good_start, len(imgsum)) if i not in bad_frame_list])],\n",
    "       title =uidstr + '_imgsum', xlabel='Frame', ylabel='Total_Intensity', legend='imgsum'   )\n",
    "    Nimg = N\n",
    "    show_img( avg_img,   vmin=None, vmax=None, logs=True, aspect=1, #save_format='tif',\n",
    "         image_name= uidstr + '_img_avg',  save=True, path=out_dir,  cmap = cmap_albula, center=center[::-1] )\n",
    "    \n",
    "    bad_frame_list =  get_bad_frame_list( imgsum, fit='both',  plot=True,polyfit_order = 30,                                      \n",
    "                        scale= 3.5,  good_start = good_start, good_end=Nimg, uid= uidstr, path=out_dir)\n",
    "    print( 'The bad frame list length is: %s'%len(bad_frame_list) )        \n",
    "    \n",
    "    imgsum_y = imgsum[ np.array( [i for i in np.arange( len(imgsum)) if i not in bad_frame_list])]\n",
    "    imgsum_x = np.arange( len( imgsum_y))\n",
    "    save_lists(  [imgsum_x, imgsum_y], label=['Frame', 'Total_Intensity'],\n",
    "           filename=uidstr + '_img_sum_t', path= data_dir  )\n",
    "    \n",
    "    plot1D( y = imgsum_y, title = uidstr + '_img_sum_t', xlabel='Frame', c='b',\n",
    "           ylabel='Total_Intensity', legend='imgsum', save=True, path=out_dir)\n",
    "    \n",
    "    if scat_geometry =='saxs':\n",
    "        ## Get circular average| * Do plot and save q~iq\n",
    "        #hmask = create_hot_pixel_mask( avg_img, threshold = 1e2, center=center, center_radius= 100)\n",
    "        #mask = mask * hmask\n",
    "        qp_saxs, iq_saxs, q_saxs = get_circular_average( avg_img, mask, pargs= setup_pargs  )\n",
    "        plot_circular_average( qp_saxs, iq_saxs, q_saxs,  pargs=setup_pargs, \n",
    "                          xlim=[q_saxs.min(), q_saxs.max()*1.0], ylim = [iq_saxs.min(), iq_saxs.max()] )\n",
    "    #mask =np.array( mask * hmask, dtype=bool)  \n",
    "\n",
    "    show_img( avg_img, label_array = roi_mask, alpha=0.4, vmin=None, vmax= None, logs=True, aspect=1, center= center[::-1],           \n",
    "         image_name= '%s_ROI_on_Image'%uidstr,  save=True, path= out_dir,  cmap = cmap_albula )\n",
    "    if scat_geometry =='saxs':\n",
    "        plot_qIq_with_ROI( q_saxs, iq_saxs, qr, logs=True, uid=uidstr, xlim=[0.002,0.006],\n",
    "                  ylim = [iq_saxs.min(), iq_saxs.max()*2],  save=True, path= out_dir)  \n",
    "    if scat_geometry =='saxs':\n",
    "        Nimg = FD.end - FD.beg \n",
    "        time_edge = create_time_slice( Nimg, slice_num= 4, slice_width= 2, edges = None )\n",
    "        time_edge =  np.array( time_edge ) #+  good_start\n",
    "        #print( time_edge )    \n",
    "        qpt, iqst, qt = get_t_iqc( FD, time_edge, mask, pargs=setup_pargs, nx=1500, show_progress= False )\n",
    "        plot_t_iqc( qt, iqst, time_edge, pargs=setup_pargs, xlim=[qt.min(), qt.max()],\n",
    "               ylim = [iqst.min(), iqst.max()], save=True )        \n",
    "\n",
    "    qind, pixelist = roi.extract_label_indices(roi_mask)\n",
    "    noqs = len(np.unique(qind))\n",
    "    nopr = np.bincount(qind, minlength=(noqs+1))[1:]\n",
    "    nopr\n",
    "    ring_avg = None    \n",
    "    if run_t_ROI_Inten:\n",
    "        times_roi, mean_int_sets = cal_each_ring_mean_intensityc(FD, roi_mask, timeperframe = None, multi_cor=True  ) \n",
    "        plot_each_ring_mean_intensityc( times_roi, mean_int_sets,  uid = uidstr, save=True, path= out_dir )\n",
    "        roi_avg = np.average( mean_int_sets, axis=0)\n",
    "    \n",
    "    # Check one ROI intensity\n",
    "    roi_inten = check_ROI_intensity( avg_img, roi_mask, ring_number= 7, uid =uidstr_ ) #roi starting from 1\n",
    "    # Do one time\n",
    "    if use_sqnorm:norm = get_pixelist_interp_iq( qp_saxs, iq_saxs, roi_mask, center)\n",
    "    else:norm=None \n",
    "    if use_imgsum_norm:imgsum_ = imgsum\n",
    "    else:imgsum_ = None    \n",
    "    import time\n",
    "    if run_one_time: \n",
    "        t0 = time.time()    \n",
    "        g2, lag_steps  = cal_g2p( FD,  roi_mask, bad_frame_list,good_start, num_buf = 8, num_lev= None,\n",
    "                                imgsum= imgsum_, norm=norm )\n",
    "        run_time(t0)\n",
    "\n",
    "    lag_steps = lag_steps[:g2.shape[0]]\n",
    "    uid_ = uidstr + '_fra_%s_%s_tbins=%.3f_ms'%(FD.beg, FD.end,  tbins*1000 )\n",
    "    timeperframe  = tbins\n",
    "    print(uid_)\n",
    "\n",
    "    if run_one_time:\n",
    "\n",
    "        taus = lag_steps * timeperframe    \n",
    "        try:\n",
    "            g2_pds = save_g2_general( g2, taus=taus,qr= np.array( list( qval_dict.values() ) )[:,0],\n",
    "                                                qz = np.array( list( qval_dict.values() ) )[:,1],\n",
    "                                 uid=uid_+'_g2.csv', path= out_dir, return_res=True )\n",
    "        except:\n",
    "            g2_pds = save_g2_general( g2, taus=taus,qr= np.array( list( qval_dict.values() ) )[:,0],                                             \n",
    "                                 uid=uid_+'_g2.csv', path= out_dir, return_res=True )\n",
    "\n",
    "    if run_one_time:\n",
    "        g2_fit_result, taus_fit, g2_fit = get_g2_fit_general( g2,  taus, \n",
    "                    function = fit_g2_func,  vlim=[0.95, 1.05], fit_range= None,  \n",
    "                fit_variables={'baseline':True, 'beta': True, 'alpha':False,'relaxation_rate':True},                                  \n",
    "                guess_values={'baseline':1.0,'beta': 0.1,'alpha':1.0,'relaxation_rate':0.0100,},\n",
    "                guess_limits = dict( baseline =[1, 1.8], alpha=[0, 2],\n",
    "                            beta = [0, 1], relaxation_rate= [0.00001, 5000]) ) \n",
    "        g2_fit_paras = save_g2_fit_para_tocsv(g2_fit_result,  filename= uid_  +'_g2_fit_paras.csv', path= out_dir )\n",
    "\n",
    "     \n",
    "\n",
    "    if run_one_time:\n",
    "        plot_g2_general( g2_dict={1:g2, 2:g2_fit}, taus_dict={1:taus, 2:taus_fit}, vlim=[0.95, 1.05],\n",
    "                    qval_dict = qval_dict, fit_res= g2_fit_result,  geometry= scat_geometry_,filename= uid_+'_g2', \n",
    "            path= out_dir, function= fit_g2_func,  ylabel='g2', append_name=  '_fit')\n",
    "  \n",
    "\n",
    "    if run_one_time:\n",
    "        if False:\n",
    "            fs, fe = 0, 9\n",
    "            fs,fe=0, 12\n",
    "            qval_dict_ = {k:qval_dict[k] for k in list(qval_dict.keys())[fs:fe]  }\n",
    "            D0, qrate_fit_res = get_q_rate_fit_general(  qval_dict_, g2_fit_paras['relaxation_rate'][fs:fe], \n",
    "                                                       geometry=  scat_geometry_ )\n",
    "            plot_q_rate_fit_general( qval_dict_, g2_fit_paras['relaxation_rate'][fs:fe],  qrate_fit_res, \n",
    "                                    geometry= scat_geometry_,uid=uid_  , path= out_dir )\n",
    "        else:\n",
    "            D0, qrate_fit_res = get_q_rate_fit_general(  qval_dict, g2_fit_paras['relaxation_rate'],\n",
    "                                        fit_range=[0, 26],   geometry= scat_geometry_ )    \n",
    "            plot_q_rate_fit_general( qval_dict, g2_fit_paras['relaxation_rate'],  qrate_fit_res,   \n",
    "                                geometry=  scat_geometry_,uid=uid_  ,\n",
    "                                    show_fit= True, path= out_dir, plot_all_range=False)\n",
    "\n",
    "    # Calculation of g2\n",
    "    if False:\n",
    "        get_diffusion_coefficient(   8.9*1e-4, 125*1e-9, T=298)/1e8 \n",
    "\n",
    "        num_bufs=8\n",
    "        noframes =  1e6\n",
    "        num_levels = int(np.log( noframes/(num_bufs-1))/np.log(2) +1) +1\n",
    "        tot_channels, lag_steps2, dict_lag = multi_tau_lags(num_levels, num_bufs)\n",
    "        max_taus= lag_steps2.max()\n",
    "        taus_ = lag_steps2 * 1e-7\n",
    "        g2_q1 = cal_particle_g2( radius=125*1e-9, viscosity=8.9*1e-4, qr=qr,  taus=taus_, beta=0.214, T=298)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        for i, q1 in enumerate(qr):\n",
    "            plot1D( x=taus_, y= g2_q1[i],   ls='-', m='', logx=True, ax =ax, c=colors[i],  legend=qr[i])\n",
    "            plot1D( x=taus[1:], y= g2[1:,i], m = markers[i], ls='', logx=True, xlim=[0.000008, 0.01], ylim=[0.98,1.22],\n",
    "                   ax =ax, c=colors[i],   legend= '')\n",
    "        fig.savefig(out_dir + uid_ + 'g2_with_cal.png')\n",
    "\n",
    "    # Two time\n",
    "    \n",
    "    define_good_series = False\n",
    "    define_good_series = True\n",
    "    if define_good_series:\n",
    "        good_start = 5\n",
    "        FD2 = Multifile(filename, beg = good_start, end = min(20000,Nimg) )\n",
    "        uid_ = uidstr + '_fra_%s_%s_tbins=%.3f_ms'%(FD2.beg, FD2.end,  tbins*1000 )\n",
    "        print( uid_ )\n",
    "    else:\n",
    "        FD2 = FD \n",
    "\n",
    "    data_pixel = None\n",
    "    if run_two_time:    \n",
    "        data_pixel =   Get_Pixel_Arrayc( FD2, pixelist,  norm= norm ).get_data()\n",
    "\n",
    "    import time\n",
    "    t0=time.time()\n",
    "    g12b=None\n",
    "    if run_two_time:     \n",
    "        g12b = auto_two_Arrayc(  data_pixel,  roi_mask, index = None   )\n",
    "        if run_dose:\n",
    "            np.save( out_dir + 'uid=%s_g12b'%uid, g12b)\n",
    "    run_time( t0 )\n",
    "\n",
    "    if run_two_time:\n",
    "        show_C12(g12b, q_ind= 6, N1= FD2.beg,logs=False, N2=min( FD2.end,100000), vmin= 1.01, vmax=1.4, \n",
    "             timeperframe=timeperframe,save=True, path= out_dir, uid = uid_ )\n",
    "\n",
    "    multi_tau_steps = True\n",
    "    if run_two_time:\n",
    "        if lag_steps is None:\n",
    "            num_bufs=8\n",
    "            noframes = FD2.end - FD2.beg\n",
    "            num_levels = int(np.log( noframes/(num_bufs-1))/np.log(2) +1) +1\n",
    "            tot_channels, lag_steps, dict_lag = multi_tau_lags(num_levels, num_bufs)\n",
    "            max_taus= lag_steps.max()\n",
    "\n",
    "        #max_taus= lag_steps.max()  \n",
    "        max_taus = N #Nimg    \n",
    "        t0=time.time()\n",
    "        #tausb = np.arange( g2b.shape[0])[:max_taus] *timeperframe\n",
    "        if multi_tau_steps:\n",
    "            lag_steps_ = lag_steps[   lag_steps <= g12b.shape[0] ]\n",
    "            g2b = get_one_time_from_two_time(g12b)[lag_steps_]\n",
    "            tausb = lag_steps_ *timeperframe\n",
    "        else:\n",
    "            tausb = (np.arange( g12b.shape[0]) *timeperframe)[:-200]\n",
    "            g2b = (get_one_time_from_two_time(g12b))[:-200]\n",
    "        run_time(t0)\n",
    "\n",
    "        g2b_pds = save_g2_general( g2b, taus=tausb, qr= np.array( list( qval_dict.values() ) )[:,0],\n",
    "                                  qz=None, uid=uid_ +'_g2b.csv', path= out_dir, return_res=True )\n",
    "\n",
    "    if run_two_time:    \n",
    "        g2b_fit_result, tausb_fit, g2b_fit = get_g2_fit_general( g2b,  tausb, \n",
    "                    function = fit_g2_func,  vlim=[0.95, 1.05], fit_range= None,  \n",
    "                fit_variables={'baseline':False, 'beta': True, 'alpha':False,'relaxation_rate':True},                                  \n",
    "                guess_values={'baseline':1.0,'beta': 0.15,'alpha':1.0,'relaxation_rate':1,},\n",
    "                guess_limits = dict( baseline =[1, 1.8], alpha=[0, 2],\n",
    "                            beta = [0, 1], relaxation_rate= [0.000001, 5000]) ) \n",
    "        g2b_fit_paras = save_g2_fit_para_tocsv(g2b_fit_result,  filename= uid_  +'_g2b_fit_paras.csv', path= out_dir )\n",
    "\n",
    "    if run_two_time:\n",
    "        plot_g2_general( g2_dict={1:g2b, 2:g2b_fit}, taus_dict={1:tausb, 2:tausb_fit}, vlim=[0.95, 1.05],\n",
    "                    qval_dict=qval_dict, fit_res= g2b_fit_result,  geometry=scat_geometry_,filename=uid_+'_g2', \n",
    "                        path= out_dir, function= fit_g2_func,  ylabel='g2', append_name=  '_b_fit')\n",
    "\n",
    "    if run_two_time:    \n",
    "        if False:\n",
    "            fs, fe = 0,9\n",
    "            fs, fe = 0,12\n",
    "            qval_dict_ = {k:qval_dict[k] for k in list(qval_dict.keys())[fs:fe]  }\n",
    "            D0b, qrate_fit_resb = get_q_rate_fit_general(  qval_dict_, g2b_fit_paras['relaxation_rate'][fs:fe], geometry= scat_geometry_ )\n",
    "            plot_q_rate_fit_general( qval_dict_, g2b_fit_paras['relaxation_rate'][fs:fe],  qrate_fit_resb, \n",
    "                                geometry= scat_geometry_,uid=uid_ +'_two_time' , path= out_dir )\n",
    "        else:\n",
    "\n",
    "            D0b, qrate_fit_resb = get_q_rate_fit_general(  qval_dict, g2b_fit_paras['relaxation_rate'],\n",
    "                                            fit_range=[1, 10],  geometry= scat_geometry_ )\n",
    "            plot_q_rate_fit_general( qval_dict, g2b_fit_paras['relaxation_rate'],  qrate_fit_resb,   \n",
    "                                geometry= scat_geometry_,uid=uid_ +'_two_time', show_fit=False,path= out_dir, plot_all_range= True )\n",
    "\n",
    "    if run_two_time and run_one_time:\n",
    "        plot_g2_general( g2_dict={1:g2, 2:g2b}, taus_dict={1:taus, 2:tausb},vlim=[0.99, 1.007],\n",
    "                    qval_dict=qval_dict, g2_labels=['from_one_time', 'from_two_time'],\n",
    "                geometry=scat_geometry_,filename=uid_+'_g2_two_g2', path= out_dir, ylabel='g2', )\n",
    "\n",
    "\n",
    "        \n",
    "    #pdf_out_dir = os.path.join('/XF11ID/analysis/', CYCLE, username, 'Results/')\n",
    "    pdf_out_dir = out_dir_\n",
    "    pdf_filename = \"XPCS_Analysis_Report_for_uid=%s%s_tbin=%s.pdf\"%(uid,pdf_version, tbins)\n",
    "\n",
    "    if run_xsvs:\n",
    "        pdf_filename = \"XPCS_XSVS_Analysis_Report_for_uid=%s%s.pdf\"%(uid,pdf_version)\n",
    "\n",
    "    print(pdf_filename)    \n",
    "    \n",
    "    username = 'yuzhang'\n",
    "    run_fit_form = False\n",
    "    run_invariant_analysis = False\n",
    "    md['beg'] = 0\n",
    "    #Nimg = N\n",
    "    md['end'] = Nimg\n",
    "    md['number of images'] = Nimg\n",
    "    md['uid_g2'] =   'run%s_pos%s_fra_%s_%s_tbins=%.3f_ms'%(run,posi+1,0,Nimg, tbins*1000)     \n",
    "    md['uid_c12'] =  'run%s_pos%s_fra_%s_%s_tbins=%.3f_ms'%(run,posi+1,FD2.beg, FD2.end, tbins*1000)\n",
    "    md['sample'] = 'SiO2_Janus_Dia250_inFuel_2%'\n",
    "    md['roi_mask_file'] =  out_dir + 'ring_roi_2017_nov24.pkl'\n",
    "\n",
    "    make_pdf_report( out_dir, uid, pdf_out_dir, pdf_filename, username, \n",
    "                    run_fit_form,run_one_time, run_two_time, run_four_time, run_xsvs, run_dose,\n",
    "                report_type= scat_geometry, report_invariant= run_invariant_analysis,\n",
    "               md = md )    \n",
    "    \n",
    "    print('*'*50)    \n",
    "    print('Finish the running of %s position.'%posi)\n",
    "    plt.close('all')\n",
    "    xeff = 0\n",
    "    yeff = 0\n",
    "    poseff = 0\n",
    "    t0eff = 0\n",
    "    teff = 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run /home/yuzhang/chxanalys_link/chxanalys/Create_Report.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    username = 'yuzhang'\n",
    "    run_fit_form = False\n",
    "    run_invariant_analysis = False\n",
    "    md['beg'] = 0\n",
    "    Nimg = N\n",
    "    md['end'] = Nimg\n",
    "    md['number of images'] = Nimg\n",
    "    md['uid_g2'] =  'run%s_pos%s_fra_%s_%s_tbins=%.3f_ms'%(run,posi+1,0,Nimg, tbins*1000)\n",
    "    md['uid_c12'] =  'run%s_pos%s_fra_%s_%s_tbins=%.3f_ms'%(run,posi+1,FD2.beg, FD2.end, tbins*1000)\n",
    "    md['sample'] = 'SiO2_Janus_Dia250_inFuel_2%'\n",
    "    md['roi_mask_file'] =  out_dir + 'ring_roi_2017_nov24.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdf_out_dir = out_dir_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    make_pdf_report( out_dir, uid, pdf_out_dir, pdf_filename, username, \n",
    "                    run_fit_form,run_one_time, run_two_time, run_four_time, run_xsvs, run_dose,\n",
    "                report_type= scat_geometry, report_invariant= run_invariant_analysis,\n",
    "               md = md ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run /home/yuzhang/chxanalys_link/chxanalys/Create_Report.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do loop here for one uid with different bin time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_dose=False\n",
    "run_two_time = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_dir0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for tbins in 0.001 * np.array( [10,1,   0.1,  0.01,  0.0075,    0.005,  0.0025, 0.001 ]):\n",
    "                          #10ms, 1ms,  100 us, 10 us, 7.5 us, 5us,   2.5us, 1us\n",
    "\n",
    "#for tbins in 0.001 * np.array( [ 0.0075  ]):        \n",
    "\n",
    "    binstep = int(tbins/time_unit)\n",
    "    tinbs = binstep * time_unit    \n",
    "    print(binstep, tinbs)\n",
    "       \n",
    "    md = { 'detector_distance': 16035 + 0,\n",
    "          'beam_center_x': 256,\n",
    "          'beam_center_y': 280,\n",
    "           'x_pixel_size': 0.045,\n",
    "          'y_pixel_size': 0.0045,\n",
    "          'incident_wavelength': 1.28481,\n",
    "          'sx': 256,\n",
    "          'sy':256,\n",
    "         'frame_time': tbins, \n",
    "          'count_time': tbins,\n",
    "           'uid': 'uid=Run11'\n",
    "         }\n",
    "\n",
    "    filename = out_dir0 + uid + '_tbin=%s.cmp'%tbins\n",
    "    if False:#consider dead time issue\n",
    "        avg_img, imgsum, N = compress_timepix_data( poseff[good_time_ind],\n",
    "                                               t0eff[good_time_ind],\n",
    "                                               binstep, filename = filename, \n",
    "                                               md = md, force_compress= True  )\n",
    "    else:        \n",
    "        avg_img, imgsum, N = compress_timepix_data( poseff,\n",
    "                                                    t0eff,\n",
    "                                               binstep, filename = filename, \n",
    "                                               md = md, force_compress= True  )\n",
    "        \n",
    "    print(N)\n",
    "    FD = Multifile(filename, 0, N  )\n",
    "    uidstr_ = uidstr + 'tbins=%.3f_ms'%( tbins*1000 ) \n",
    "    \n",
    "    plot1D( x = tbins* np.arange(len(imgsum)), \n",
    "           y= imgsum , m='o', c='b', ls = '--',save=True, path= out_dir,\n",
    "         title='%s_imgsum_time'%(uidstr),\n",
    "           xlabel = r\"$time $ $(s)$\", ylabel = 'Photon Counts of Image Sum' )\n",
    "    \n",
    "    # Check one ROI intensity\n",
    "    roi_inten = check_ROI_intensity( avg_img, roi_mask, ring_number= 7, uid =uidstr_ ) #roi starting from 1\n",
    "    # Do one time\n",
    "    if use_sqnorm:norm = get_pixelist_interp_iq( qp_saxs, iq_saxs, roi_mask, center)\n",
    "    else:norm=None \n",
    "    if use_imgsum_norm:imgsum_ = imgsum\n",
    "    else:imgsum_ = None    \n",
    "    import time\n",
    "    if run_one_time: \n",
    "        t0 = time.time()    \n",
    "        g2, lag_steps  = cal_g2p( FD,  roi_mask, bad_frame_list,good_start, num_buf = 8, num_lev= None,\n",
    "                                imgsum= imgsum_, norm=norm )\n",
    "        run_time(t0)\n",
    "\n",
    "    lag_steps = lag_steps[:g2.shape[0]]\n",
    "    uid_ = uidstr + '_fra_%s_%s_tbins=%.3f_ms'%(FD.beg, FD.end,  tbins*1000 )\n",
    "    timeperframe  = tbins\n",
    "    print(uid_)\n",
    "\n",
    "    if run_one_time:\n",
    "\n",
    "        taus = lag_steps * timeperframe    \n",
    "        try:\n",
    "            g2_pds = save_g2_general( g2, taus=taus,qr= np.array( list( qval_dict.values() ) )[:,0],\n",
    "                                                qz = np.array( list( qval_dict.values() ) )[:,1],\n",
    "                                 uid=uid_+'_g2.csv', path= out_dir, return_res=True )\n",
    "        except:\n",
    "            g2_pds = save_g2_general( g2, taus=taus,qr= np.array( list( qval_dict.values() ) )[:,0],                                             \n",
    "                                 uid=uid_+'_g2.csv', path= out_dir, return_res=True )\n",
    "\n",
    "    if run_one_time:\n",
    "        g2_fit_result, taus_fit, g2_fit = get_g2_fit_general( g2,  taus, \n",
    "                    function = fit_g2_func,  vlim=[0.95, 1.05], fit_range= None,  \n",
    "                fit_variables={'baseline':True, 'beta': True, 'alpha':False,'relaxation_rate':True},                                  \n",
    "                guess_values={'baseline':1.0,'beta': 0.1,'alpha':1.0,'relaxation_rate':0.0100,},\n",
    "                guess_limits = dict( baseline =[1, 1.8], alpha=[0, 2],\n",
    "                            beta = [0, 1], relaxation_rate= [0.00001, 5000]) ) \n",
    "        g2_fit_paras = save_g2_fit_para_tocsv(g2_fit_result,  filename= uid_  +'_g2_fit_paras.csv', path= out_dir )\n",
    "\n",
    "     \n",
    "\n",
    "    if run_one_time:\n",
    "        plot_g2_general( g2_dict={1:g2, 2:g2_fit}, taus_dict={1:taus, 2:taus_fit}, vlim=[0.95, 1.05],\n",
    "                    qval_dict = qval_dict, fit_res= g2_fit_result,  geometry= scat_geometry_,filename= uid_+'_g2', \n",
    "            path= out_dir, function= fit_g2_func,  ylabel='g2', append_name=  '_fit')\n",
    "  \n",
    "\n",
    "    if run_one_time:\n",
    "        if False:\n",
    "            fs, fe = 0, 9\n",
    "            fs,fe=0, 12\n",
    "            qval_dict_ = {k:qval_dict[k] for k in list(qval_dict.keys())[fs:fe]  }\n",
    "            D0, qrate_fit_res = get_q_rate_fit_general(  qval_dict_, g2_fit_paras['relaxation_rate'][fs:fe], \n",
    "                                                       geometry=  scat_geometry_ )\n",
    "            plot_q_rate_fit_general( qval_dict_, g2_fit_paras['relaxation_rate'][fs:fe],  qrate_fit_res, \n",
    "                                    geometry= scat_geometry_,uid=uid_  , path= out_dir )\n",
    "        else:\n",
    "            D0, qrate_fit_res = get_q_rate_fit_general(  qval_dict, g2_fit_paras['relaxation_rate'],\n",
    "                                        fit_range=[0, 26],   geometry= scat_geometry_ )    \n",
    "            plot_q_rate_fit_general( qval_dict, g2_fit_paras['relaxation_rate'],  qrate_fit_res,   \n",
    "                                geometry=  scat_geometry_,uid=uid_  ,\n",
    "                                    show_fit= True, path= out_dir, plot_all_range=False)\n",
    "\n",
    "    # Calculation of g2\n",
    "\n",
    "    get_diffusion_coefficient(   8.9*1e-4, 125*1e-9, T=298)/1e8 \n",
    "\n",
    "    num_bufs=8\n",
    "    noframes =  1e6\n",
    "    num_levels = int(np.log( noframes/(num_bufs-1))/np.log(2) +1) +1\n",
    "    tot_channels, lag_steps2, dict_lag = multi_tau_lags(num_levels, num_bufs)\n",
    "    max_taus= lag_steps2.max()\n",
    "    taus_ = lag_steps2 * 1e-7\n",
    "    g2_q1 = cal_particle_g2( radius=125*1e-9, viscosity=8.9*1e-4, qr=qr,  taus=taus_, beta=0.214, T=298)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    for i, q1 in enumerate(qr):\n",
    "        plot1D( x=taus_, y= g2_q1[i],   ls='-', m='', logx=True, ax =ax, c=colors[i],  legend=qr[i])\n",
    "        plot1D( x=taus[1:], y= g2[1:,i], m = markers[i], ls='', logx=True, xlim=[0.000008, 0.01], ylim=[0.98,1.22],\n",
    "               ax =ax, c=colors[i],   legend= '')\n",
    "    fig.savefig(out_dir + uid_ + 'g2_with_cal.png')\n",
    "\n",
    "    # Two time\n",
    "    define_good_series = False\n",
    "    #define_good_series = True\n",
    "    if define_good_series:\n",
    "        good_start = 5\n",
    "        FD = Multifile(filename, beg = good_start, end = 1000)\n",
    "        uid_ = uidstr + '_fra_%s_%s'%(FD.beg, FD.end)\n",
    "        print( uid_ )\n",
    "\n",
    "    data_pixel = None\n",
    "    if run_two_time:    \n",
    "        data_pixel =   Get_Pixel_Arrayc( FD, pixelist,  norm= norm ).get_data()\n",
    "\n",
    "    import time\n",
    "    t0=time.time()\n",
    "    g12b=None\n",
    "    if run_two_time:     \n",
    "        g12b = auto_two_Arrayc(  data_pixel,  roi_mask, index = None   )\n",
    "        if run_dose:\n",
    "            np.save( out_dir + 'uid=%s_g12b'%uid, g12b)\n",
    "    run_time( t0 )\n",
    "\n",
    "    if run_two_time:\n",
    "        show_C12(g12b, q_ind= 7, N1= FD.beg,logs=False, N2=min( FD.end,10000), vmin= 1.01, vmax=1.4, \n",
    "                 timeperframe=timeperframe,save=True, path= out_dir, uid = uid_ )\n",
    "\n",
    "    multi_tau_steps = True\n",
    "    if run_two_time:\n",
    "        if lag_steps is None:\n",
    "            num_bufs=8\n",
    "            noframes = FD.end - FD.beg\n",
    "            num_levels = int(np.log( noframes/(num_bufs-1))/np.log(2) +1) +1\n",
    "            tot_channels, lag_steps, dict_lag = multi_tau_lags(num_levels, num_bufs)\n",
    "            max_taus= lag_steps.max()\n",
    "\n",
    "        #max_taus= lag_steps.max()  \n",
    "        max_taus = N #Nimg    \n",
    "        t0=time.time()\n",
    "        #tausb = np.arange( g2b.shape[0])[:max_taus] *timeperframe\n",
    "        if multi_tau_steps:\n",
    "            lag_steps_ = lag_steps[   lag_steps <= g12b.shape[0] ]\n",
    "            g2b = get_one_time_from_two_time(g12b)[lag_steps_]\n",
    "            tausb = lag_steps_ *timeperframe\n",
    "        else:\n",
    "            tausb = (np.arange( g12b.shape[0]) *timeperframe)[:-200]\n",
    "            g2b = (get_one_time_from_two_time(g12b))[:-200]\n",
    "        run_time(t0)\n",
    "\n",
    "        g2b_pds = save_g2_general( g2b, taus=tausb, qr= np.array( list( qval_dict.values() ) )[:,0],\n",
    "                                  qz=None, uid=uid_ +'_g2b.csv', path= out_dir, return_res=True )\n",
    "\n",
    "    if run_two_time:    \n",
    "        g2b_fit_result, tausb_fit, g2b_fit = get_g2_fit_general( g2b,  tausb, \n",
    "                    function = fit_g2_func,  vlim=[0.95, 1.05], fit_range= None,  \n",
    "                fit_variables={'baseline':False, 'beta': True, 'alpha':False,'relaxation_rate':True},                                  \n",
    "                guess_values={'baseline':1.0,'beta': 0.15,'alpha':1.0,'relaxation_rate':1,},\n",
    "                guess_limits = dict( baseline =[1, 1.8], alpha=[0, 2],\n",
    "                            beta = [0, 1], relaxation_rate= [0.000001, 5000]) ) \n",
    "        g2b_fit_paras = save_g2_fit_para_tocsv(g2b_fit_result,  filename= uid_  +'_g2b_fit_paras.csv', path= out_dir )\n",
    "\n",
    "    if run_two_time:\n",
    "        plot_g2_general( g2_dict={1:g2b, 2:g2b_fit}, taus_dict={1:tausb, 2:tausb_fit}, vlim=[0.95, 1.05],\n",
    "                    qval_dict=qval_dict, fit_res= g2b_fit_result,  geometry=scat_geometry_,filename=uid_+'_g2', \n",
    "                        path= out_dir, function= fit_g2_func,  ylabel='g2', append_name=  '_b_fit')\n",
    "\n",
    "    if run_two_time:    \n",
    "        if False:\n",
    "            fs, fe = 0,9\n",
    "            fs, fe = 0,12\n",
    "            qval_dict_ = {k:qval_dict[k] for k in list(qval_dict.keys())[fs:fe]  }\n",
    "            D0b, qrate_fit_resb = get_q_rate_fit_general(  qval_dict_, g2b_fit_paras['relaxation_rate'][fs:fe], geometry= scat_geometry_ )\n",
    "            plot_q_rate_fit_general( qval_dict_, g2b_fit_paras['relaxation_rate'][fs:fe],  qrate_fit_resb, \n",
    "                                geometry= scat_geometry_,uid=uid_ +'_two_time' , path= out_dir )\n",
    "        else:\n",
    "\n",
    "            D0b, qrate_fit_resb = get_q_rate_fit_general(  qval_dict, g2b_fit_paras['relaxation_rate'],\n",
    "                                            fit_range=[1, 10],  geometry= scat_geometry_ )\n",
    "            plot_q_rate_fit_general( qval_dict, g2b_fit_paras['relaxation_rate'],  qrate_fit_resb,   \n",
    "                                geometry= scat_geometry_,uid=uid_ +'_two_time', show_fit=False,path= out_dir, plot_all_range= True )\n",
    "\n",
    "    if run_two_time and run_one_time:\n",
    "        plot_g2_general( g2_dict={1:g2, 2:g2b}, taus_dict={1:taus, 2:tausb},vlim=[0.99, 1.007],\n",
    "                    qval_dict=qval_dict, g2_labels=['from_one_time', 'from_two_time'],\n",
    "                geometry=scat_geometry_,filename=uid_+'_g2_two_g2', path= out_dir, ylabel='g2', )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Depedent I(q) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if scat_geometry =='saxs':\n",
    "    Nimg = FD.end - FD.beg \n",
    "    time_edge = create_time_slice( Nimg, slice_num= 8, slice_width= 2, edges = None )\n",
    "    time_edge =  np.array( time_edge ) + good_start\n",
    "    #print( time_edge )    \n",
    "    qpt, iqst, qt = get_t_iqc( FD, time_edge, mask, pargs=setup_pargs, nx=1500, show_progress= False )\n",
    "    plot_t_iqc( qt, iqst, time_edge, pargs=setup_pargs, xlim=[qt.min(), qt.max()],\n",
    "           ylim = [iqst.min(), iqst.max()], save=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do a waterfall analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ring_avg = None    \n",
    "if run_t_ROI_Inten:\n",
    "    times_roi, mean_int_sets = cal_each_ring_mean_intensityc(FD, roi_mask, timeperframe = None, multi_cor=True  ) \n",
    "    plot_each_ring_mean_intensityc( times_roi, mean_int_sets,  uid = uidstr, save=True, path= out_dir )\n",
    "    roi_avg = np.average( mean_int_sets, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CHX (legacy 2016)",
   "language": "python",
   "name": "stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
